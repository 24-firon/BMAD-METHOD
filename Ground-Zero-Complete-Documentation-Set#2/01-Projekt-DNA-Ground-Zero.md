# 01 â€“ Projekt-DNA: Ground-Zero Agency Infrastructure

**Version:** 1.0  
**Phase:** Ãœbergreifend (1-3)  
**SÃ¤ulen:** A (Desktop) + B (Maschinenraum) + C (Sanctum)  
**Datum:** 2025-11-19  

---

## ğŸ§¬ Worum es bei Ground-Zero wirklich geht

Ground-Zero ist kein Tool-Sammelsurium und kein Experimentierspielplatz â€“ es ist ein **dreischichtiges Betriebssystem fÃ¼r eine Solo-KI-Agentur**, das bewusst so gebaut ist, dass es mit minimaler manueller Arbeit skaliert, auditierbar bleibt und bei Ausfall in wenigen Stunden wiederherstellbar ist.

Die Kernidee stammt aus der Erkenntnis, dass â€klassisches" LLM-Prompting (freie Chat-Befehle, viele Tool-Definitionen im Kontext, stÃ¤ndiges Copy-Paste) **exponentiell ineffizient** wird, sobald man mehr als 5-10 Workflows, mehrere Mandanten und echte Compliance-Anforderungen hat. Ground-Zero lÃ¶st das durch:

1. **MCP-First-Architektur** â€“ Tools sind klar definierte, wiederverwendbare Bausteine mit Schemas, nicht Ad-hoc-Prompts.
2. **PostgreSQL als Single Source of Truth** â€“ Alle relevanten Daten (n8n-State, Agent-Queues, E2B-Logs, spÃ¤ter Analytics) landen in einem Cluster.
3. **Drei-SÃ¤ulen-Modell** â€“ Kommandozentrale (Desktop), Maschinenraum (Droplets) und Sanctum (Agent-Zero) sind klar getrennt, aber logisch verzahnt.
4. **Phasen-Denken** â€“ Phase 1 (lokal/MCP), Phase 2 (Server/n8n), Phase 3 (Enterprise/OpenBao/Prometheus) als bewusste Eskalations-Stufen, nicht als â€irgendwann mal"-Wishlist.

Das Projekt heiÃŸt â€Ground-Zero", weil es bewusst **bei Null anfÃ¤ngt** â€“ mit klaren Regeln, sauberen Grenzen und dem Ziel, dass jede Entscheidung (Technologie, Prozess, Dokumentation) **nachvollziehbar und reproduzierbar** ist.

### ğŸ¯ Veranschaulichung â€“ Die drei SÃ¤ulen im Ãœberblick

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SÃ„ULE A: Kommandozentrale (Desktop)              â”‚
â”‚   - Windows 11 + WSL2 + Docker Desktop             â”‚
â”‚   - Claude Desktop + MCP-Server (Python)           â”‚
â”‚   - E2B-Sandboxes, Skills, Repo-Verwaltung         â”‚
â”‚   Rolle: Planung, Steuerung, lokale Tests          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚  steuert
                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SÃ„ULE B: Maschinenraum (Droplets + Docker)       â”‚
â”‚   - Postgres 16 (zentraler Datenpool)              â”‚
â”‚   - n8n (Workflow-Orchestrierung)                  â”‚
â”‚   - Backup/DR-Skripte, Monitoring-Basics           â”‚
â”‚   Rolle: DauerlÃ¤ufer, Datenhaltung, Automation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚  liefert Jobs/Logs
                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SÃ„ULE C: Sanctum (Agent-Zero-Zone)               â”‚
â”‚   - Agent-Zero Engine Ã¼ber Queue-Tabellen          â”‚
â”‚   - Optional: lokaler LLM fÃ¼r sensible Analysen    â”‚
â”‚   Rolle: GeschÃ¼tzter Analyse-Kern, Offline-Tasks   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        Quer dazu: Monitoring, Compliance, DR
```

---

## ğŸ§± Die SÃ¤ulen im Detail

### SÃ¤ule A: Kommandozentrale (Desktop)

**Zweck:** Deine physische Arbeitsumgebung â€“ hier entstehen Konfigurationen, werden Tests gefahren, Skills geschrieben und MCP-Tools orchestriert.

**Bestandteile:**
- **Windows 11** als Host fÃ¼r Editor (VSCode/Cursor), Git, Claude Desktop
- **WSL2 (Ubuntu)** als Linux-Runtime fÃ¼r Docker und Python-MCP-Server
- **Docker Desktop** fÃ¼r lokale Container (Postgres-Tests, E2B-Sandboxes)
- **Python 3.10+** als MCP-Runtime (bewusst Python statt Node/npm fÃ¼r Kern-Tools)
- **Claude Desktop + MCP-Client** als Haupt-UI fÃ¼r Tool-Aufrufe
- **Repos** (`claude-agents`, `ground-zero-infra`) fÃ¼r Architektur, Docs, Skripte

**Wichtigste Dokumente auf Desktop-Ebene:**
- `projektdaten.md` â€“ der â€Speicher" fÃ¼r aktuelle Entscheidungen
- `GROUND-ZERO-FINAL-ARCHITEKTUR.md` â€“ Zielbild
- `ERKENNTNISSE_KOMPLETT.md` â€“ Design-Prinzipien aus Sessions
- Skill-Blueprints, automation-helpers.sh, Phase-Docs

**Rolle im System:**
SÃ¤ule A ist **nicht** der Ort, wo produktive Workflows laufen â€“ das macht SÃ¤ule B. Stattdessen ist A der Ort, wo du **planst, konfigurierst, testest und debuggst**, bevor Ã„nderungen auf den Droplets landen.

#### ğŸ“Š Veranschaulichung â€“ Desktop-Stack-Komponenten

| Ebene | Komponente | Aufgabe | Phase |
|-------|-----------|---------|-------|
| Host | Windows 11 | GUI, Editor, Git, Claude Desktop | 1+ |
| VM | WSL2 (Ubuntu) | Docker + Python-Runtime | 1+ |
| Runtime | Python 3.10+ | MCP-Server, E2B-Clients | 1+ |
| LLM | Claude Desktop | MCP-Tool-Orchestrierung | 1+ |
| Wissen | projektdaten.md, Final-Architektur, Erkenntnisse | Projekt-DNA | 1-3 |

---

### SÃ¤ule B: Maschinenraum (Droplets + Docker-Stack)

**Zweck:** Die produktive Laufzeitumgebung â€“ hier laufen n8n, Postgres, Agent-Zero-Service, E2B-Sandbox-Container und alle DauerlÃ¤ufer.

**Bestandteile:**
- **DigitalOcean Droplet(s)** (Ubuntu-Server) mit Docker Engine
- **PostgreSQL 16-Alpine** als zentraler Datenpool (n8n-DB, Agent-Zero-Queues, E2B-Logs, spÃ¤ter Analytics)
- **n8n** (Workflow-Engine) fÃ¼r GitHub-Events, Cron-Jobs, GDPR-Flows, Monitoring-Workflows
- **Agent-Zero-Service** (optional in Phase 2, fest in Phase 3) fÃ¼r Queue-basierte Aufgaben
- **E2B-Sandbox-Container** fÃ¼r isolierte Code-Execution
- **Reverse-Proxy** (Caddy/Traefik) fÃ¼r TLS-Termination und Routing
- **Optional:** Redis (Caching), Worker (Hintergrund-Jobs)

**Zentrale Artefakte:**
- `docker-compose.yml` â€“ Definition aller Services
- `.env` / `env.example` â€“ Umgebungsvariablen-Struktur
- `n8n-postgres-stack.yaml` â€“ Infra-Spec fÃ¼r Stack
- Backup-Skripte (`pg-backup.sh`, `pg-restore.sh`)
- Monitoring-Skripte (`system-audit.sh`, Health-Checks)

**Rolle im System:**
SÃ¤ule B ist der **DauerlÃ¤ufer** â€“ alles, was 24/7 erreichbar sein muss, lÃ¤uft hier. Ã„nderungen an B werden immer von A aus geplant und getestet, nie direkt auf dem Live-System editiert.

#### ğŸ“Š Veranschaulichung â€“ Maschinenraum-Services

| Service | Image | Rolle | AbhÃ¤ngigkeiten |
|---------|-------|-------|----------------|
| `postgres` | `postgres:16-alpine` | Zentrale DB (n8n, Queues, Logs) | â€“ |
| `n8n` | `n8nio/n8n:latest` | Workflow-Orchestrierung | postgres |
| `agent-zero` | `groundzero/agent-zero:latest` | Queue-basierte Jobs | postgres |
| `e2b-sandbox` | `e2b/sandbox:latest` | Isolierte Code-Execution | â€“ |
| `redis` | `redis:alpine` (optional) | Caching/Queue | â€“ |
| `reverse-proxy` | `caddy:latest` | TLS-Termination, Routing | n8n, agent-zero |

---

### SÃ¤ule C: Sanctum (Agent-Zero-Zone)

**Zweck:** Der geschÃ¼tzte Analyse-Kern â€“ hier laufen sensible, rechenintensive oder Offline-Tasks, die nicht direkt im Internet hÃ¤ngen.

**Bestandteile:**
- **Agent-Zero Engine** als eigenstÃ¤ndiger Service (Container in SÃ¤ule B, aber logisch getrennt)
- **Queue-Tabellen** in Postgres (`agent_zero_queue`, `agent_zero_results`) als einzige Kommunikationsschnittstelle
- **Optional:** Lokaler LLM (Ollama/ggml-Modelle) fÃ¼r Analysen ohne Cloud-Abfluss
- **Audit-Tabellen** fÃ¼r nachvollziehbare Job-Historie

**Kommunikations-Pattern:**
Sanctum spricht **nie direkt** mit dem Internet oder anderen Services â€“ alle Inputs kommen Ã¼ber Queue-Tabellen, alle Outputs gehen zurÃ¼ck in Result-Tabellen.

**Rolle im System:**
SÃ¤ule C ist der Ort fÃ¼r:
- Komplexe Log-Analysen
- Security-Bewertungen
- Mehrstufige Compliance-Checks
- Query-Optimierung
- Dinge, die â€zu schwer" fÃ¼r n8n-Workflows sind

#### ğŸ” Veranschaulichung â€“ Agent-Zero-Queue-Flow

```text
[n8n / Desktop / andere Dienste]
           |
           |  schreibt Job (JSON Payload, PrioritÃ¤t)
           v
   [agent_zero_queue]  (Postgres-Tabelle)
           |
           |  Agent-Zero pollt neue Jobs
           v
      [Agent-Zero Engine]
           |
           |  fÃ¼hrt Aufgabe aus (z.B. Log-Analyse)
           v
   [agent_zero_results] (Postgres-Tabelle)
           |
           |  n8n/Clients lesen Ergebnis
           v
      [Reports / weitere Flows]
```

---

## ğŸš¦ Die drei Phasen als Eskalations-Stufen

Ground-Zero ist nicht â€alles auf einmal", sondern bewusst in **drei Ausbaustufen** gedacht, die jeweils neue Funktionen und KomplexitÃ¤t einfÃ¼hren.

### Phase 1: MCP-First (lokal, kein produktiver Server)

**Status:** Aktuell  
**Fokus:** Desktop-Stack, MCP-Server, E2B-Tests, Skills-Setup  
**SÃ¤ulen aktiv:** Nur A (Desktop)  

**Was lÃ¤uft:**
- Claude Desktop + Python-MCP-Server (STDIO-Transport)
- Lokale Docker-Container fÃ¼r Tests (Postgres-Instanzen, E2B-Sandboxes)
- Skills (Droplet-Diagnostics, n8n-Health, Repo-Maintenance, Docker-Cleanup) in `.claude/skills`
- Repo-Verwaltung (`claude-agents`, `ground-zero-infra`)

**Was NICHT lÃ¤uft:**
- Kein produktiver Droplet-Stack
- Kein n8n in Produktion
- Keine Agent-Zero-Engine
- Keine produktiven Backups/DR

**Ziel von Phase 1:**
Einen **stabilen, wiederholbaren Desktop-Setup** haben, der:
- MCP-Tools sauber registriert und aufrufbar macht
- E2B-Sandboxes starten und steuern kann
- Skills und Skripte testet, ohne Live-Systeme zu gefÃ¤hrden

**Typische AktivitÃ¤ten:**
- `automation-helpers.sh` entwickeln und testen
- MCP-Manifest (`groundzero-mcp-manifest.json`) entwerfen
- Skill-Blueprints ausarbeiten
- Projektdaten/Final-Architektur pflegen

---

### Phase 2: Server-Stack (n8n + Postgres + Monitoring-Basics)

**Status:** Geplant (nÃ¤chste Stufe)  
**Fokus:** Droplet-Rebuild, docker-compose-Stack, n8n-Workflows, Backup/DR, Monitoring  
**SÃ¤ulen aktiv:** A (Desktop) + B (Maschinenraum)  

**Was neu hinzukommt:**
- **Produktiver Droplet** mit `docker-compose.yml`-Stack (Postgres, n8n, Caddy, optional Redis)
- **n8n-Workflow-Library** (8-12 Standard-Workflows: GitHub-Automation, Health-Checks, Backup-Trigger, GDPR-Flows)
- **Backup/DR-Skripte** (`pg-backup.sh`, `pg-restore.sh`, Validation-Script) mit 3-2-1-Strategie
- **Monitoring-Basics** (Logs, Healthchecks, Alerts, wÃ¶chentliches `system-audit.sh`)
- **Security-Baseline** (SSH-Keys, UFW, Fail2ban, Auto-Updates)

**Was noch NICHT lÃ¤uft:**
- Kein OpenBao (Secrets noch in `.env`)
- Kein Prometheus/Grafana (nur Shell-Checks + Cron)
- Agent-Zero optional als Proof-of-Concept, nicht als Voll-Setup

**Ziel von Phase 2:**
Einen **produktiven, aber minimal komplexen Server-Stack** haben, der:
- RTO < 4 h, RPO < 24 h erfÃ¼llt
- 90% Compliance-Threshold schafft (wÃ¶chentliches Audit-Script)
- n8n-Workflows fÃ¼r GitHub, Monitoring und GDPR orchestriert
- Vom Desktop aus steuerbar ist (MCP-Tools + Skills)

**Typische AktivitÃ¤ten:**
- Droplet provisionieren, `docker-compose up -d`
- n8n-Workflows importieren, testen, dokumentieren
- Backup-Job in Cron einrichten, ersten Game-Day fahren
- Monitoring-Alerts (Email + optional Webhook) konfigurieren

---

### Phase 3: Enterprise-Level (OpenBao, Prometheus, Voll-Sanctum)

**Status:** Vision (lÃ¤ngerfristig)  
**Fokus:** Secrets-Management, vollwertige Observability, Agent-Zero produktiv, Analytics  
**SÃ¤ulen aktiv:** A + B + C (alle)  

**Was neu hinzukommt:**
- **OpenBao** als Vault-Ersatz fÃ¼r Secrets (statt `.env`)
- **Prometheus + Grafana** fÃ¼r Metriken, Dashboards, SLO-basierte Alerts
- **Loki / ELK** fÃ¼r zentrale Log-Aggregation
- **Agent-Zero Engine** als produktiver Service mit Queue-Tabellen
- **Optional:** Lokaler LLM (Ollama) in Sanctum
- **Multi-Tenant-Support** via PostgreSQL RLS
- **SLA-Monitoring** mit Breach-Notifier, Reports

**Ziel von Phase 3:**
Ein **Enterprise-taugliches Setup**, das:
- Secrets rotiert und auditiert (OpenBao)
- SLOs definiert und Ã¼berwacht (Prometheus/Grafana)
- Komplexe Analysen in Sanctum auslagert (Agent-Zero)
- Skaliert auf 1000+ Tasks/Woche

**Trigger fÃ¼r Phase 3:**
- Phase 2 lÃ¤uft stabil (mehrere Monate)
- Backup/DR mehrfach getestet
- Mandanten-Daten wachsen (Multi-Tenant wird relevant)
- OpenBao-Migration geplant (Secrets-Rotation nÃ¶tig)

---

## ğŸ§  Kern-Prinzipien (die "DNA")

### 1. Editor statt Chatbot

**Was es bedeutet:**  
Prompts, Playbooks, Skripte und Konfigs sind **Artefakte wie Infrastructure as Code** â€“ sie werden in Git versioniert, in Markdown/YAML/Python geschrieben und systematisch gepflegt, nicht als Wegwerf-Chat-Text behandelt.

**Praktisch:**
- Skill-Definitionen liegen in `.claude/skills/*.md`
- MCP-Tools haben JSON-Schemas in einem Manifest
- Workflows sind in n8n dokumentiert oder als YAML-Snippets exportiert
- Projektdaten/Final-Architektur sind die â€Quelle der Wahrheit", nicht Chat-Historie

**Warum:**
Weil â€Frage im Chat â†’ neue Antwort" **nicht skaliert**, sobald du mehr als 5 Workflows hast oder nach einer Pause zurÃ¼ckkommst. Mit versionierten Artefakten kannst du jederzeit nachvollziehen, was du wann entschieden hast.

---

### 2. MCP-First & Hybrid-Execution

**Was es bedeutet:**  
Tools sind **klar definierte, wiederverwendbare Bausteine** (MCP-Tools mit Schemas), nicht Ad-hoc-Shell-Befehle. Code-Execution lÃ¤uft **isoliert** (E2B-Sandboxes), nicht direkt auf deinem Host oder Droplet.

**Praktisch:**
- Claude Desktop ruft `tools/http.get`, `tools/fs.read`, `tools/e2b.run` auf â€“ nicht â€fÃ¼hre diesen Bash-Befehl aus"
- E2B-Sandboxes kapseln riskante/schwere Operationen (Magic-MCP-Server, groÃŸe Scripts)
- Cloud-Code (GitHub Actions) fÃ¼r wiederkehrende, skalierbare Tasks

**Warum:**
Der MCP-Report zeigt: Klassische Tool-Nutzung (alle Definitionen + Zwischenergebnisse im Prompt) explodiert bei 20+ Tools. Mit MCP/E2B sparst du **98,7% Token** und hast gleichzeitig bessere Auditierbarkeit.

---

### 3. PostgreSQL als Single Source of Truth

**Was es bedeutet:**  
Alle relevanten Daten landen in **einem PostgreSQL-16-Cluster** â€“ n8n-State, Agent-Zero-Queues, E2B-Logs, spÃ¤ter Analytics, GDPR-Audit-Logs, SLA-Metriken.

**Praktisch:**
- n8n nutzt Postgres statt SQLite
- Agent-Zero schreibt Jobs in `agent_zero_queue`, Results in `agent_zero_results`
- Backups sichern **nur** diesen einen Cluster (plus `.env`/Compose als Konfig)
- Kein zweiter MySQL, kein MongoDB, keine verteilten Datenbanken

**Warum:**
Weil **ein Restore-Punkt** viel einfacher ist als â€5 Datenbanken + 3 File-Systeme + 2 Caches". RTO < 4 h ist realistisch, wenn du nur Postgres + Compose wiederherstellen musst.

---

### 4. Drei-SÃ¤ulen-Trennung (Separation of Concerns)

**Was es bedeutet:**  
Desktop (A) steuert, Maschinenraum (B) fÃ¼hrt aus, Sanctum (C) analysiert â€“ **niemals vermischen**.

**Praktisch:**
- Du editierst nie direkt auf dem Droplet (kein `vim docker-compose.yml` auf dem Server)
- Agent-Zero hat keinen direkten Internet-Zugang, nur Queue-Tabellen
- MCP-Tools auf Desktop kÃ¶nnen Droplet-Skripte **anstoÃŸen**, aber nicht unkontrolliert Shell-Befehle ausfÃ¼hren

**Warum:**
Weil **klare Grenzen** Fehler reduzieren und Audits ermÃ¶glichen. Wenn jeder Layer seinen Scope hat, kannst du schnell erkennen, wo ein Problem liegt.

---

### 5. Phasen-Denken (keine Big-Bang-Migration)

**Was es bedeutet:**  
Jede Phase baut auf der vorherigen auf, aber **fÃ¼hrt neue KomplexitÃ¤t nur ein, wenn die alte stabil ist**.

**Praktisch:**
- Phase 1: MCP lokal testen, bevor du Droplets anfasst
- Phase 2: n8n + Monitoring-Basics laufen lassen, bevor Prometheus kommt
- Phase 3: OpenBao erst, wenn Secrets-Rotation wirklich nÃ¶tig wird

**Warum:**
Weil â€alles auf einmal" in 99% der FÃ¤lle scheitert. Mit klaren Phasen kannst du jederzeit pausieren und hast trotzdem ein funktionierendes System.

---

### 6. Compliance & DR als First-Class-Themen

**Was es bedeutet:**  
Backup, Monitoring, Security und GDPR sind **keine Add-Ons**, sondern von Anfang an eingeplant.

**Praktisch:**
- RTO < 4 h, RPO < 24 h als harte Ziele in Phase 2
- WÃ¶chentliches `system-audit.sh` mit 90% Pass-Threshold
- GDPR-Flows (Auskunft, LÃ¶schung) als n8n-Workflows in Phase 2
- 3-2-1-Backup (3 Kopien, 2 Medien, 1 Offsite) von Tag 1

**Warum:**
Weil â€spÃ¤ter kÃ¼mmern wir uns um Backups" in der RealitÃ¤t nie passiert. Mit klaren RTO/RPO-Zielen und wÃ¶chentlichen Audits **merkst du sofort**, wenn etwas kaputt geht.

---

## âš ï¸ Harte Regeln (Non-Negotiable)

Diese Regeln gelten **immer**, in allen Phasen, fÃ¼r alle Agents:

1. **Keine Shell-Execs durch KI ohne Freigabe** â€“ KIs dÃ¼rfen Skripte vorschlagen, aber nicht eigenmÃ¤chtig auf Produktivsystemen ausfÃ¼hren.
2. **Keine Browser-Storage-APIs in Artifacts** â€“ `localStorage`, `sessionStorage`, `document.cookie` werfen SecurityError in Sandboxes.
3. **Keine Secrets in Git/Logs** â€“ `.env` ist gitignored, Secrets werden nie geloggt.
4. **Backup vor jedem groÃŸen Change** â€“ Vor Postgres-Migrationen, Compose-Ã„nderungen, Server-Rebuilds immer Backup.
5. **WÃ¶chentliches Audit-Script muss laufen** â€“ Wenn `system-audit.sh` < 90% Pass hat, **sofort reagieren**.
6. **MCP-Tools nur mit Whitelists** â€“ Erlaubte Pfade/Kommandos explizit definiert, alles andere Tabu.
7. **Ã„nderungen an SÃ¤ule B nur von SÃ¤ule A aus** â€“ Nie direkt auf Droplet editieren.
8. **Skills/Agents mÃ¼ssen Guardrails haben** â€“ Jeder Skill definiert erlaubte/verbotene Pfade und Kommandos.

---

## ğŸ”— Wie alles zusammenhÃ¤ngt

### Datenfluss (vereinfacht)

```text
[Du / Editor]
      |
      v
[Claude Desktop + MCP-Client]
      |
      v
[MCP-Server (Python)]
      |
      +--> [Filesystem] (projektdaten.md, Skripte, Skills)
      |
      +--> [E2B-Sandbox] (isolierte Code-Exec)
      |
      +--> [HTTP-APIs] (GitHub, DO, n8n-Health)
      |
      v
[Droplet: docker-compose-Stack]
      |
      +--> [Postgres] <-- [n8n] <-- [GitHub-Webhooks]
      |
      +--> [Agent-Zero] <-- [Queue-Tabellen]
      |
      +--> [Backup-Skripte] --> [Offsite-Storage]
      |
      v
[Monitoring/Alerts] --> [Email / Webhook]
```

### Workflow-Beispiel: GitHub Issue â†’ n8n â†’ Postgres â†’ Agent-Zero

1. **GitHub Issue erstellt** â†’ Webhook an n8n
2. **n8n-Workflow** "GitHub Issue â†’ Postgres Log"  
   - Extrahiert Issue-Daten (Titel, Body, Labels)
   - Schreibt in `github_events`-Tabelle (Postgres)
3. **Optional:** n8n schreibt Job in `agent_zero_queue`  
   - Payload: `{ "type": "analyze_issue", "issue_id": 123 }`
4. **Agent-Zero** pollt Queue, sieht neuen Job  
   - LÃ¤dt Issue-Daten aus Postgres
   - FÃ¼hrt Analyse aus (z.B. Sentiment, Kategorisierung)
   - Schreibt Ergebnis in `agent_zero_results`
5. **n8n-Workflow** "Agent-Zero Result â†’ GitHub Comment"  
   - Liest Result aus Postgres
   - Postet Analyse als GitHub-Comment

---

## ğŸ“Š Wichtigste Metriken & Ziele

| Metrik | Ziel | Phase | Verifizierung |
|--------|------|-------|---------------|
| RTO (Recovery Time Objective) | < 4 h | 2 | Game-Day-Tests, DR-Runbook |
| RPO (Recovery Point Objective) | < 24 h | 2 | TÃ¤gliche Backups, Validierung |
| Compliance-Pass-Rate | â‰¥ 90% | 2 | WÃ¶chentlich `system-audit.sh` |
| Backup-Frequenz | TÃ¤glich | 2 | Cron + Monitoring-Alert |
| MCP-Tool-Registrierung | 6-10 Tools | 1 | Manifest + Desktop-Test |
| n8n-Workflow-Library | 8-12 Workflows | 2 | Workflow-Doku + Tests |
| Skills aktiv | 4-6 Skills | 1-2 | `.claude/skills/` + Tests |

---

## ğŸš€ NÃ¤chste Schritte (Phase 1 â†’ Phase 2)

### Phase 1 abschlieÃŸen (aktuell)
- [ ] Python-MCP-Server mit 6+ Tools produktiv
- [ ] E2B-Sandbox-Tests erfolgreich
- [ ] Skills (Droplet-Diagnostics, n8n-Health, Repo-Maintenance, Docker-Cleanup) getestet
- [ ] `automation-helpers.sh` funktional
- [ ] Projektdaten/Final-Architektur aktuell

### Phase 2 vorbereiten
- [ ] Droplet-Analyse (bestehende Server, VPN, SSH-Keys)
- [ ] `docker-compose.yml` final (Postgres, n8n, Caddy, optional Redis)
- [ ] `env.example` mit allen Keys
- [ ] Backup-Skripte (`pg-backup.sh`, `pg-restore.sh`) geschrieben
- [ ] Monitoring-Skripte (`system-audit.sh`, Health-Checks) vorbereitet

### Phase 2 starten
- [ ] Droplet provisionieren (Ubuntu, Docker, UFW, Fail2ban)
- [ ] `docker-compose up -d`, Health-Checks verifizieren
- [ ] n8n-Workflow-Library importieren
- [ ] Backup-Cron einrichten, ersten Backup-Test fahren
- [ ] Ersten Game-Day durchfÃ¼hren (RTO/RPO messen)

---

## ğŸ“ Ã„nderungs-Historie

| Datum | Version | Ã„nderung |
|-------|---------|----------|
| 2025-11-19 | 1.0 | Initial â€“ VollstÃ¤ndige DNA-Beschreibung aus allen Quellen synthetisiert |

---

*Dieses Kapitel bildet die Grundlage fÃ¼r alle weiteren Dokumente. Lies es zuerst, bevor du in Details einsteigst.*
